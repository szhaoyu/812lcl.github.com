{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist-torch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6hGYMQjGZDTqghEB3KXXG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szhaoyu/812lcl.github.com/blob/master/mnist_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTvy0f3GSfOk",
        "outputId": "e8cefcf8-e932-45b0-c6c0-2009d4734dfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement matploblib (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for matploblib\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "!pip install tqdm\n",
        "!pip install matploblib\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "\n",
        "from tqdm import tqdm\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
        "                                torchvision.transforms.Normalize(mean = [0.5],std = [0.5])])\n"
      ],
      "metadata": {
        "id": "dAVSIbmaTAck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "id": "6n8-2-bqUX6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0e3fb47-fda1-4a74-8c43-196beb625fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = './data/'  #数据集下载后保存的目录\n",
        "trainData = torchvision.datasets.MNIST(path, train = True, transform = transform,download = True)\n",
        "testData = torchvision.datasets.MNIST(path, train = False, transform = transform,download = True)\n"
      ],
      "metadata": {
        "id": "QVLRlT6vTGUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 256  \n",
        "trainDataLoader = torch.utils.data.DataLoader(dataset = trainData,batch_size = BATCH_SIZE,shuffle = True)\n",
        "testDataLoader = torch.utils.data.DataLoader(dataset = testData,batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "id": "8-eymitkTVwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        self.model = torch.nn.Sequential(\n",
        "            #The size of the picture is 28x28\n",
        "            torch.nn.Conv2d(in_channels = 1,out_channels = 16,kernel_size = 3,stride = 1,padding = 1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
        "            \n",
        "            #The size of the picture is 14x14\n",
        "            torch.nn.Conv2d(in_channels = 16,out_channels = 32,kernel_size = 3,stride = 1,padding = 1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
        "            \n",
        "            #The size of the picture is 7x7\n",
        "            torch.nn.Conv2d(in_channels = 32,out_channels = 64,kernel_size = 3,stride = 1,padding = 1),\n",
        "            torch.nn.ReLU(),\n",
        "            \n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Linear(in_features = 7 * 7 * 64,out_features = 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(in_features = 128,out_features = 10),\n",
        "            torch.nn.Softmax(dim=1)\n",
        "        )\n",
        "        \n",
        "    def forward(self,input):\n",
        "        output = self.model(input)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "Dop2lyEHTitM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "#将模型转换到device中，并将其结构显示出来\n",
        "print(net.to(device)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcLnfHjNTmWS",
        "outputId": "69925e1b-a100-4cae-bc99-9fb0d9beed64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU()\n",
            "    (8): Flatten(start_dim=1, end_dim=-1)\n",
            "    (9): Linear(in_features=3136, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=10, bias=True)\n",
            "    (12): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lossF = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "processBar = tqdm(trainDataLoader,unit = 'step')\n",
        "net.train(True)\n",
        "\n",
        "EPOCHS = 10\n",
        "#存储训练过程\n",
        "history = {'Test Loss':[],'Test Accuracy':[]}\n",
        "for epoch in range(1,EPOCHS + 1):\n",
        "    processBar = tqdm(trainDataLoader,unit = 'step')\n",
        "    net.train(True)\n",
        "    for step,(trainImgs,labels) in enumerate(processBar):\n",
        "        trainImgs = trainImgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        net.zero_grad()\n",
        "        outputs = net(trainImgs)\n",
        "        loss = lossF(outputs,labels)\n",
        "        predictions = torch.argmax(outputs, dim = 1)\n",
        "        accuracy = torch.sum(predictions == labels)/labels.shape[0]\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        processBar.set_description(\"[%d/%d] Loss: %.4f, Acc: %.4f\" % \n",
        "                                   (epoch,EPOCHS,loss.item(),accuracy.item()))\n",
        "        \n",
        "        if step == len(processBar)-1:\n",
        "            correct,totalLoss = 0,0\n",
        "            net.train(False)\n",
        "            for testImgs,labels in testDataLoader:\n",
        "                testImgs = testImgs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = net(testImgs)\n",
        "                loss = lossF(outputs,labels)\n",
        "                predictions = torch.argmax(outputs,dim = 1)\n",
        "                \n",
        "                totalLoss += loss\n",
        "                correct += torch.sum(predictions == labels)\n",
        "            testAccuracy = correct/(BATCH_SIZE * len(testDataLoader))\n",
        "            testLoss = totalLoss/len(testDataLoader)\n",
        "            history['Test Loss'].append(testLoss.item())\n",
        "            history['Test Accuracy'].append(testAccuracy.item())\n",
        "            processBar.set_description(\"[%d/%d] Loss: %.4f, Acc: %.4f, Test Loss: %.4f, Test Acc: %.4f\" % \n",
        "                                   (epoch,EPOCHS,loss.item(),accuracy.item(),testLoss.item(),testAccuracy.item()))\n",
        "    processBar.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLXqDYTDTqM7",
        "outputId": "98707299-7e4e-4255-8081-96aa42354a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/235 [00:00<?, ?step/s]\n",
            "  0%|          | 0/235 [00:00<?, ?step/s]\n",
            "\n",
            "[1/10] Loss: 2.3013, Acc: 0.1133:   0%|          | 0/235 [00:00<?, ?step/s]\u001b[A\n",
            "[1/10] Loss: 2.3013, Acc: 0.1133:   0%|          | 1/235 [00:00<00:57,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 2.3014, Acc: 0.0898:   0%|          | 1/235 [00:00<00:57,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 2.3014, Acc: 0.0898:   1%|          | 2/235 [00:00<00:58,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 2.2945, Acc: 0.1094:   1%|          | 2/235 [00:00<00:58,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 2.2945, Acc: 0.1094:   1%|▏         | 3/235 [00:00<00:57,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 2.2940, Acc: 0.1797:   1%|▏         | 3/235 [00:00<00:57,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 2.2940, Acc: 0.1797:   2%|▏         | 4/235 [00:00<00:56,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 2.2849, Acc: 0.0977:   2%|▏         | 4/235 [00:01<00:56,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 2.2849, Acc: 0.0977:   2%|▏         | 5/235 [00:01<00:54,  4.20step/s]\u001b[A\n",
            "[1/10] Loss: 2.2731, Acc: 0.3086:   2%|▏         | 5/235 [00:01<00:54,  4.20step/s]\u001b[A\n",
            "[1/10] Loss: 2.2731, Acc: 0.3086:   3%|▎         | 6/235 [00:01<00:57,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 2.2548, Acc: 0.4297:   3%|▎         | 6/235 [00:01<00:57,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 2.2548, Acc: 0.4297:   3%|▎         | 7/235 [00:01<00:56,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 2.2479, Acc: 0.2344:   3%|▎         | 7/235 [00:01<00:56,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 2.2479, Acc: 0.2344:   3%|▎         | 8/235 [00:01<00:56,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 2.2333, Acc: 0.2422:   3%|▎         | 8/235 [00:02<00:56,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 2.2333, Acc: 0.2422:   4%|▍         | 9/235 [00:02<00:54,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 2.2230, Acc: 0.2344:   4%|▍         | 9/235 [00:02<00:54,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 2.2230, Acc: 0.2344:   4%|▍         | 10/235 [00:02<00:54,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 2.2069, Acc: 0.2422:   4%|▍         | 10/235 [00:02<00:54,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 2.2069, Acc: 0.2422:   5%|▍         | 11/235 [00:02<00:55,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 2.1726, Acc: 0.3711:   5%|▍         | 11/235 [00:02<00:55,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 2.1726, Acc: 0.3711:   5%|▌         | 12/235 [00:02<00:53,  4.16step/s]\u001b[A\n",
            "[1/10] Loss: 2.1616, Acc: 0.4258:   5%|▌         | 12/235 [00:03<00:53,  4.16step/s]\u001b[A\n",
            "[1/10] Loss: 2.1616, Acc: 0.4258:   6%|▌         | 13/235 [00:03<00:53,  4.12step/s]\u001b[A\n",
            "[1/10] Loss: 2.1240, Acc: 0.4570:   6%|▌         | 13/235 [00:03<00:53,  4.12step/s]\u001b[A\n",
            "[1/10] Loss: 2.1240, Acc: 0.4570:   6%|▌         | 14/235 [00:03<00:54,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 2.0674, Acc: 0.4570:   6%|▌         | 14/235 [00:03<00:54,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 2.0674, Acc: 0.4570:   6%|▋         | 15/235 [00:03<00:53,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 2.1093, Acc: 0.3359:   6%|▋         | 15/235 [00:03<00:53,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 2.1093, Acc: 0.3359:   7%|▋         | 16/235 [00:03<00:52,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 2.0346, Acc: 0.4609:   7%|▋         | 16/235 [00:04<00:52,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 2.0346, Acc: 0.4609:   7%|▋         | 17/235 [00:04<00:52,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 2.0601, Acc: 0.4375:   7%|▋         | 17/235 [00:04<00:52,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 2.0601, Acc: 0.4375:   8%|▊         | 18/235 [00:04<00:54,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.9742, Acc: 0.6211:   8%|▊         | 18/235 [00:04<00:54,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.9742, Acc: 0.6211:   8%|▊         | 19/235 [00:04<00:54,  3.96step/s]\u001b[A\n",
            "[1/10] Loss: 2.0070, Acc: 0.5000:   8%|▊         | 19/235 [00:04<00:54,  3.96step/s]\u001b[A\n",
            "[1/10] Loss: 2.0070, Acc: 0.5000:   9%|▊         | 20/235 [00:04<00:53,  3.98step/s]\u001b[A\n",
            "[1/10] Loss: 1.9573, Acc: 0.5430:   9%|▊         | 20/235 [00:05<00:53,  3.98step/s]\u001b[A\n",
            "[1/10] Loss: 1.9573, Acc: 0.5430:   9%|▉         | 21/235 [00:05<00:54,  3.95step/s]\u001b[A\n",
            "[1/10] Loss: 1.9419, Acc: 0.5703:   9%|▉         | 21/235 [00:05<00:54,  3.95step/s]\u001b[A\n",
            "[1/10] Loss: 1.9419, Acc: 0.5703:   9%|▉         | 22/235 [00:05<00:53,  3.97step/s]\u001b[A\n",
            "[1/10] Loss: 1.9462, Acc: 0.5430:   9%|▉         | 22/235 [00:05<00:53,  3.97step/s]\u001b[A\n",
            "[1/10] Loss: 1.9462, Acc: 0.5430:  10%|▉         | 23/235 [00:05<00:52,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.8848, Acc: 0.6328:  10%|▉         | 23/235 [00:05<00:52,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.8848, Acc: 0.6328:  10%|█         | 24/235 [00:05<00:51,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.8972, Acc: 0.6094:  10%|█         | 24/235 [00:06<00:51,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.8972, Acc: 0.6094:  11%|█         | 25/235 [00:06<00:50,  4.19step/s]\u001b[A\n",
            "[1/10] Loss: 1.8791, Acc: 0.5977:  11%|█         | 25/235 [00:06<00:50,  4.19step/s]\u001b[A\n",
            "[1/10] Loss: 1.8791, Acc: 0.5977:  11%|█         | 26/235 [00:06<00:50,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.8872, Acc: 0.5703:  11%|█         | 26/235 [00:06<00:50,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.8872, Acc: 0.5703:  11%|█▏        | 27/235 [00:06<00:51,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.8257, Acc: 0.6562:  11%|█▏        | 27/235 [00:06<00:51,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.8257, Acc: 0.6562:  12%|█▏        | 28/235 [00:06<00:50,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.8188, Acc: 0.6641:  12%|█▏        | 28/235 [00:07<00:50,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.8188, Acc: 0.6641:  12%|█▏        | 29/235 [00:07<00:50,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.8030, Acc: 0.6992:  12%|█▏        | 29/235 [00:07<00:50,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.8030, Acc: 0.6992:  13%|█▎        | 30/235 [00:07<00:50,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.8124, Acc: 0.6680:  13%|█▎        | 30/235 [00:07<00:50,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.8124, Acc: 0.6680:  13%|█▎        | 31/235 [00:07<00:50,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.7990, Acc: 0.6523:  13%|█▎        | 31/235 [00:07<00:50,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.7990, Acc: 0.6523:  14%|█▎        | 32/235 [00:07<00:50,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.8410, Acc: 0.6406:  14%|█▎        | 32/235 [00:08<00:50,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.8410, Acc: 0.6406:  14%|█▍        | 33/235 [00:08<00:49,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.7789, Acc: 0.7031:  14%|█▍        | 33/235 [00:08<00:49,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.7789, Acc: 0.7031:  14%|█▍        | 34/235 [00:08<00:48,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.7238, Acc: 0.7539:  14%|█▍        | 34/235 [00:08<00:48,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.7238, Acc: 0.7539:  15%|█▍        | 35/235 [00:08<00:47,  4.17step/s]\u001b[A\n",
            "[1/10] Loss: 1.7880, Acc: 0.6875:  15%|█▍        | 35/235 [00:08<00:47,  4.17step/s]\u001b[A\n",
            "[1/10] Loss: 1.7880, Acc: 0.6875:  15%|█▌        | 36/235 [00:08<00:49,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.7719, Acc: 0.6992:  15%|█▌        | 36/235 [00:09<00:49,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.7719, Acc: 0.6992:  16%|█▌        | 37/235 [00:09<00:48,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.8131, Acc: 0.6445:  16%|█▌        | 37/235 [00:09<00:48,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.8131, Acc: 0.6445:  16%|█▌        | 38/235 [00:09<00:48,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.7732, Acc: 0.6914:  16%|█▌        | 38/235 [00:09<00:48,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.7732, Acc: 0.6914:  17%|█▋        | 39/235 [00:09<00:48,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.7583, Acc: 0.7031:  17%|█▋        | 39/235 [00:09<00:48,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.7583, Acc: 0.7031:  17%|█▋        | 40/235 [00:09<00:47,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.7557, Acc: 0.7109:  17%|█▋        | 40/235 [00:10<00:47,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.7557, Acc: 0.7109:  17%|█▋        | 41/235 [00:10<00:46,  4.20step/s]\u001b[A\n",
            "[1/10] Loss: 1.7524, Acc: 0.7188:  17%|█▋        | 41/235 [00:10<00:46,  4.20step/s]\u001b[A\n",
            "[1/10] Loss: 1.7524, Acc: 0.7188:  18%|█▊        | 42/235 [00:10<00:45,  4.21step/s]\u001b[A\n",
            "[1/10] Loss: 1.7618, Acc: 0.7031:  18%|█▊        | 42/235 [00:10<00:45,  4.21step/s]\u001b[A\n",
            "[1/10] Loss: 1.7618, Acc: 0.7031:  18%|█▊        | 43/235 [00:10<00:45,  4.20step/s]\u001b[A\n",
            "[1/10] Loss: 1.7105, Acc: 0.7578:  18%|█▊        | 43/235 [00:10<00:45,  4.20step/s]\u001b[A\n",
            "[1/10] Loss: 1.7105, Acc: 0.7578:  19%|█▊        | 44/235 [00:10<00:45,  4.15step/s]\u001b[A\n",
            "[1/10] Loss: 1.7833, Acc: 0.6875:  19%|█▊        | 44/235 [00:10<00:45,  4.15step/s]\u001b[A\n",
            "[1/10] Loss: 1.7833, Acc: 0.6875:  19%|█▉        | 45/235 [00:11<00:45,  4.19step/s]\u001b[A\n",
            "[1/10] Loss: 1.6831, Acc: 0.7969:  19%|█▉        | 45/235 [00:11<00:45,  4.19step/s]\u001b[A\n",
            "[1/10] Loss: 1.6831, Acc: 0.7969:  20%|█▉        | 46/235 [00:11<00:44,  4.21step/s]\u001b[A\n",
            "[1/10] Loss: 1.7398, Acc: 0.7422:  20%|█▉        | 46/235 [00:11<00:44,  4.21step/s]\u001b[A\n",
            "[1/10] Loss: 1.7398, Acc: 0.7422:  20%|██        | 47/235 [00:11<00:45,  4.15step/s]\u001b[A\n",
            "[1/10] Loss: 1.6877, Acc: 0.7852:  20%|██        | 47/235 [00:11<00:45,  4.15step/s]\u001b[A\n",
            "[1/10] Loss: 1.6877, Acc: 0.7852:  20%|██        | 48/235 [00:11<00:45,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.7005, Acc: 0.7812:  20%|██        | 48/235 [00:11<00:45,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.7005, Acc: 0.7812:  21%|██        | 49/235 [00:11<00:44,  4.16step/s]\u001b[A\n",
            "[1/10] Loss: 1.6913, Acc: 0.7891:  21%|██        | 49/235 [00:12<00:44,  4.16step/s]\u001b[A\n",
            "[1/10] Loss: 1.6913, Acc: 0.7891:  21%|██▏       | 50/235 [00:12<00:44,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 1.6828, Acc: 0.7969:  21%|██▏       | 50/235 [00:12<00:44,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 1.6828, Acc: 0.7969:  22%|██▏       | 51/235 [00:12<00:44,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 1.6402, Acc: 0.8438:  22%|██▏       | 51/235 [00:12<00:44,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 1.6402, Acc: 0.8438:  22%|██▏       | 52/235 [00:12<00:44,  4.12step/s]\u001b[A\n",
            "[1/10] Loss: 1.6470, Acc: 0.8281:  22%|██▏       | 52/235 [00:12<00:44,  4.12step/s]\u001b[A\n",
            "[1/10] Loss: 1.6470, Acc: 0.8281:  23%|██▎       | 53/235 [00:12<00:45,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6176, Acc: 0.8555:  23%|██▎       | 53/235 [00:13<00:45,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6176, Acc: 0.8555:  23%|██▎       | 54/235 [00:13<00:44,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6430, Acc: 0.8242:  23%|██▎       | 54/235 [00:13<00:44,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6430, Acc: 0.8242:  23%|██▎       | 55/235 [00:13<00:44,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6373, Acc: 0.8281:  23%|██▎       | 55/235 [00:13<00:44,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6373, Acc: 0.8281:  24%|██▍       | 56/235 [00:13<00:43,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 1.7084, Acc: 0.7578:  24%|██▍       | 56/235 [00:13<00:43,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 1.7084, Acc: 0.7578:  24%|██▍       | 57/235 [00:13<00:43,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.6868, Acc: 0.7734:  24%|██▍       | 57/235 [00:14<00:43,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.6868, Acc: 0.7734:  25%|██▍       | 58/235 [00:14<00:42,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 1.6528, Acc: 0.8047:  25%|██▍       | 58/235 [00:14<00:42,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 1.6528, Acc: 0.8047:  25%|██▌       | 59/235 [00:14<00:42,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 1.6168, Acc: 0.8555:  25%|██▌       | 59/235 [00:14<00:42,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 1.6168, Acc: 0.8555:  26%|██▌       | 60/235 [00:14<00:41,  4.18step/s]\u001b[A\n",
            "[1/10] Loss: 1.6557, Acc: 0.8164:  26%|██▌       | 60/235 [00:14<00:41,  4.18step/s]\u001b[A\n",
            "[1/10] Loss: 1.6557, Acc: 0.8164:  26%|██▌       | 61/235 [00:14<00:42,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.6385, Acc: 0.8203:  26%|██▌       | 61/235 [00:15<00:42,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.6385, Acc: 0.8203:  26%|██▋       | 62/235 [00:15<00:41,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 1.6363, Acc: 0.8359:  26%|██▋       | 62/235 [00:15<00:41,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 1.6363, Acc: 0.8359:  27%|██▋       | 63/235 [00:15<00:41,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6572, Acc: 0.8047:  27%|██▋       | 63/235 [00:15<00:41,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6572, Acc: 0.8047:  27%|██▋       | 64/235 [00:15<00:41,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.6124, Acc: 0.8594:  27%|██▋       | 64/235 [00:15<00:41,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.6124, Acc: 0.8594:  28%|██▊       | 65/235 [00:15<00:41,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6403, Acc: 0.8281:  28%|██▊       | 65/235 [00:16<00:41,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6403, Acc: 0.8281:  28%|██▊       | 66/235 [00:16<00:41,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6112, Acc: 0.8555:  28%|██▊       | 66/235 [00:16<00:41,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6112, Acc: 0.8555:  29%|██▊       | 67/235 [00:16<00:41,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6344, Acc: 0.8281:  29%|██▊       | 67/235 [00:16<00:41,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6344, Acc: 0.8281:  29%|██▉       | 68/235 [00:16<00:41,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.6568, Acc: 0.8164:  29%|██▉       | 68/235 [00:16<00:41,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.6568, Acc: 0.8164:  29%|██▉       | 69/235 [00:16<00:41,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6241, Acc: 0.8359:  29%|██▉       | 69/235 [00:17<00:41,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6241, Acc: 0.8359:  30%|██▉       | 70/235 [00:17<00:40,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6633, Acc: 0.8086:  30%|██▉       | 70/235 [00:17<00:40,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6633, Acc: 0.8086:  30%|███       | 71/235 [00:17<00:40,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6247, Acc: 0.8555:  30%|███       | 71/235 [00:17<00:40,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6247, Acc: 0.8555:  31%|███       | 72/235 [00:17<00:40,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.6823, Acc: 0.7852:  31%|███       | 72/235 [00:17<00:40,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.6823, Acc: 0.7852:  31%|███       | 73/235 [00:17<00:40,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6538, Acc: 0.8203:  31%|███       | 73/235 [00:18<00:40,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6538, Acc: 0.8203:  31%|███▏      | 74/235 [00:18<00:39,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6318, Acc: 0.8359:  31%|███▏      | 74/235 [00:18<00:39,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6318, Acc: 0.8359:  32%|███▏      | 75/235 [00:18<00:39,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6364, Acc: 0.8281:  32%|███▏      | 75/235 [00:18<00:39,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6364, Acc: 0.8281:  32%|███▏      | 76/235 [00:18<00:39,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.5767, Acc: 0.9023:  32%|███▏      | 76/235 [00:18<00:39,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.5767, Acc: 0.9023:  33%|███▎      | 77/235 [00:18<00:38,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6491, Acc: 0.8203:  33%|███▎      | 77/235 [00:19<00:38,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6491, Acc: 0.8203:  33%|███▎      | 78/235 [00:19<00:38,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.6050, Acc: 0.8633:  33%|███▎      | 78/235 [00:19<00:38,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.6050, Acc: 0.8633:  34%|███▎      | 79/235 [00:19<00:38,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6246, Acc: 0.8398:  34%|███▎      | 79/235 [00:19<00:38,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6246, Acc: 0.8398:  34%|███▍      | 80/235 [00:19<00:38,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6777, Acc: 0.7812:  34%|███▍      | 80/235 [00:19<00:38,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6777, Acc: 0.7812:  34%|███▍      | 81/235 [00:19<00:37,  4.12step/s]\u001b[A\n",
            "[1/10] Loss: 1.6282, Acc: 0.8320:  34%|███▍      | 81/235 [00:20<00:37,  4.12step/s]\u001b[A\n",
            "[1/10] Loss: 1.6282, Acc: 0.8320:  35%|███▍      | 82/235 [00:20<00:37,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.6306, Acc: 0.8438:  35%|███▍      | 82/235 [00:20<00:37,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.6306, Acc: 0.8438:  35%|███▌      | 83/235 [00:20<00:37,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.6238, Acc: 0.8438:  35%|███▌      | 83/235 [00:20<00:37,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.6238, Acc: 0.8438:  36%|███▌      | 84/235 [00:20<00:37,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6234, Acc: 0.8438:  36%|███▌      | 84/235 [00:20<00:37,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6234, Acc: 0.8438:  36%|███▌      | 85/235 [00:20<00:36,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6036, Acc: 0.8672:  36%|███▌      | 85/235 [00:21<00:36,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6036, Acc: 0.8672:  37%|███▋      | 86/235 [00:21<00:36,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6258, Acc: 0.8477:  37%|███▋      | 86/235 [00:21<00:36,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6258, Acc: 0.8477:  37%|███▋      | 87/235 [00:21<00:36,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.6270, Acc: 0.8359:  37%|███▋      | 87/235 [00:21<00:36,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.6270, Acc: 0.8359:  37%|███▋      | 88/235 [00:21<00:36,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6712, Acc: 0.7969:  37%|███▋      | 88/235 [00:21<00:36,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6712, Acc: 0.7969:  38%|███▊      | 89/235 [00:21<00:36,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.6256, Acc: 0.8398:  38%|███▊      | 89/235 [00:22<00:36,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.6256, Acc: 0.8398:  38%|███▊      | 90/235 [00:22<00:36,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6327, Acc: 0.8281:  38%|███▊      | 90/235 [00:22<00:36,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6327, Acc: 0.8281:  39%|███▊      | 91/235 [00:22<00:35,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6619, Acc: 0.7969:  39%|███▊      | 91/235 [00:22<00:35,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6619, Acc: 0.7969:  39%|███▉      | 92/235 [00:22<00:35,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.6494, Acc: 0.8164:  39%|███▉      | 92/235 [00:22<00:35,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.6494, Acc: 0.8164:  40%|███▉      | 93/235 [00:22<00:34,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6071, Acc: 0.8594:  40%|███▉      | 93/235 [00:23<00:34,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6071, Acc: 0.8594:  40%|████      | 94/235 [00:23<00:35,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6087, Acc: 0.8555:  40%|████      | 94/235 [00:23<00:35,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6087, Acc: 0.8555:  40%|████      | 95/235 [00:23<00:34,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6125, Acc: 0.8555:  40%|████      | 95/235 [00:23<00:34,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6125, Acc: 0.8555:  41%|████      | 96/235 [00:23<00:34,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6125, Acc: 0.8555:  41%|████      | 96/235 [00:23<00:34,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6125, Acc: 0.8555:  41%|████▏     | 97/235 [00:23<00:34,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6334, Acc: 0.8281:  41%|████▏     | 97/235 [00:24<00:34,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6334, Acc: 0.8281:  42%|████▏     | 98/235 [00:24<00:33,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6493, Acc: 0.8242:  42%|████▏     | 98/235 [00:24<00:33,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6493, Acc: 0.8242:  42%|████▏     | 99/235 [00:24<00:33,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6106, Acc: 0.8555:  42%|████▏     | 99/235 [00:24<00:33,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6106, Acc: 0.8555:  43%|████▎     | 100/235 [00:24<00:33,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.5766, Acc: 0.8867:  43%|████▎     | 100/235 [00:24<00:33,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.5766, Acc: 0.8867:  43%|████▎     | 101/235 [00:24<00:33,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.5993, Acc: 0.8711:  43%|████▎     | 101/235 [00:25<00:33,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.5993, Acc: 0.8711:  43%|████▎     | 102/235 [00:25<00:32,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6398, Acc: 0.8281:  43%|████▎     | 102/235 [00:25<00:32,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6398, Acc: 0.8281:  44%|████▍     | 103/235 [00:25<00:32,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6189, Acc: 0.8398:  44%|████▍     | 103/235 [00:25<00:32,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6189, Acc: 0.8398:  44%|████▍     | 104/235 [00:25<00:32,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.5941, Acc: 0.8672:  44%|████▍     | 104/235 [00:25<00:32,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.5941, Acc: 0.8672:  45%|████▍     | 105/235 [00:25<00:32,  3.95step/s]\u001b[A\n",
            "[1/10] Loss: 1.5900, Acc: 0.8789:  45%|████▍     | 105/235 [00:26<00:32,  3.95step/s]\u001b[A\n",
            "[1/10] Loss: 1.5900, Acc: 0.8789:  45%|████▌     | 106/235 [00:26<00:32,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.6056, Acc: 0.8594:  45%|████▌     | 106/235 [00:26<00:32,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.6056, Acc: 0.8594:  46%|████▌     | 107/235 [00:26<00:32,  3.98step/s]\u001b[A\n",
            "[1/10] Loss: 1.6514, Acc: 0.8203:  46%|████▌     | 107/235 [00:26<00:32,  3.98step/s]\u001b[A\n",
            "[1/10] Loss: 1.6514, Acc: 0.8203:  46%|████▌     | 108/235 [00:26<00:32,  3.95step/s]\u001b[A\n",
            "[1/10] Loss: 1.6081, Acc: 0.8555:  46%|████▌     | 108/235 [00:26<00:32,  3.95step/s]\u001b[A\n",
            "[1/10] Loss: 1.6081, Acc: 0.8555:  46%|████▋     | 109/235 [00:26<00:31,  3.95step/s]\u001b[A\n",
            "[1/10] Loss: 1.6259, Acc: 0.8359:  46%|████▋     | 109/235 [00:27<00:31,  3.95step/s]\u001b[A\n",
            "[1/10] Loss: 1.6259, Acc: 0.8359:  47%|████▋     | 110/235 [00:27<00:31,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.5968, Acc: 0.8672:  47%|████▋     | 110/235 [00:27<00:31,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.5968, Acc: 0.8672:  47%|████▋     | 111/235 [00:27<00:32,  3.87step/s]\u001b[A\n",
            "[1/10] Loss: 1.6288, Acc: 0.8359:  47%|████▋     | 111/235 [00:27<00:32,  3.87step/s]\u001b[A\n",
            "[1/10] Loss: 1.6288, Acc: 0.8359:  48%|████▊     | 112/235 [00:27<00:31,  3.90step/s]\u001b[A\n",
            "[1/10] Loss: 1.6014, Acc: 0.8672:  48%|████▊     | 112/235 [00:27<00:31,  3.90step/s]\u001b[A\n",
            "[1/10] Loss: 1.6014, Acc: 0.8672:  48%|████▊     | 113/235 [00:27<00:31,  3.93step/s]\u001b[A\n",
            "[1/10] Loss: 1.6160, Acc: 0.8594:  48%|████▊     | 113/235 [00:28<00:31,  3.93step/s]\u001b[A\n",
            "[1/10] Loss: 1.6160, Acc: 0.8594:  49%|████▊     | 114/235 [00:28<00:29,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.5896, Acc: 0.8789:  49%|████▊     | 114/235 [00:28<00:29,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.5896, Acc: 0.8789:  49%|████▉     | 115/235 [00:28<00:29,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6222, Acc: 0.8516:  49%|████▉     | 115/235 [00:28<00:29,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6222, Acc: 0.8516:  49%|████▉     | 116/235 [00:28<00:28,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6245, Acc: 0.8398:  49%|████▉     | 116/235 [00:28<00:28,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6245, Acc: 0.8398:  50%|████▉     | 117/235 [00:28<00:29,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6012, Acc: 0.8633:  50%|████▉     | 117/235 [00:29<00:29,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6012, Acc: 0.8633:  50%|█████     | 118/235 [00:29<00:28,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6237, Acc: 0.8359:  50%|█████     | 118/235 [00:29<00:28,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6237, Acc: 0.8359:  51%|█████     | 119/235 [00:29<00:28,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6408, Acc: 0.8242:  51%|█████     | 119/235 [00:29<00:28,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6408, Acc: 0.8242:  51%|█████     | 120/235 [00:29<00:28,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6187, Acc: 0.8516:  51%|█████     | 120/235 [00:29<00:28,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6187, Acc: 0.8516:  51%|█████▏    | 121/235 [00:29<00:28,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.5941, Acc: 0.8750:  51%|█████▏    | 121/235 [00:30<00:28,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.5941, Acc: 0.8750:  52%|█████▏    | 122/235 [00:30<00:27,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6191, Acc: 0.8398:  52%|█████▏    | 122/235 [00:30<00:27,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6191, Acc: 0.8398:  52%|█████▏    | 123/235 [00:30<00:27,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.6437, Acc: 0.8242:  52%|█████▏    | 123/235 [00:30<00:27,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.6437, Acc: 0.8242:  53%|█████▎    | 124/235 [00:30<00:27,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.6345, Acc: 0.8281:  53%|█████▎    | 124/235 [00:30<00:27,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.6345, Acc: 0.8281:  53%|█████▎    | 125/235 [00:30<00:27,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6064, Acc: 0.8594:  53%|█████▎    | 125/235 [00:30<00:27,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6064, Acc: 0.8594:  54%|█████▎    | 126/235 [00:30<00:26,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6037, Acc: 0.8594:  54%|█████▎    | 126/235 [00:31<00:26,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6037, Acc: 0.8594:  54%|█████▍    | 127/235 [00:31<00:26,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6168, Acc: 0.8477:  54%|█████▍    | 127/235 [00:31<00:26,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6168, Acc: 0.8477:  54%|█████▍    | 128/235 [00:31<00:26,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.6389, Acc: 0.8203:  54%|█████▍    | 128/235 [00:31<00:26,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.6389, Acc: 0.8203:  55%|█████▍    | 129/235 [00:31<00:26,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6114, Acc: 0.8477:  55%|█████▍    | 129/235 [00:31<00:26,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6114, Acc: 0.8477:  55%|█████▌    | 130/235 [00:31<00:25,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.5958, Acc: 0.8750:  55%|█████▌    | 130/235 [00:32<00:25,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.5958, Acc: 0.8750:  56%|█████▌    | 131/235 [00:32<00:25,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6470, Acc: 0.8242:  56%|█████▌    | 131/235 [00:32<00:25,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6470, Acc: 0.8242:  56%|█████▌    | 132/235 [00:32<00:25,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.6428, Acc: 0.8203:  56%|█████▌    | 132/235 [00:32<00:25,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.6428, Acc: 0.8203:  57%|█████▋    | 133/235 [00:32<00:25,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6415, Acc: 0.8203:  57%|█████▋    | 133/235 [00:32<00:25,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6415, Acc: 0.8203:  57%|█████▋    | 134/235 [00:32<00:24,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6168, Acc: 0.8477:  57%|█████▋    | 134/235 [00:33<00:24,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6168, Acc: 0.8477:  57%|█████▋    | 135/235 [00:33<00:24,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.6212, Acc: 0.8398:  57%|█████▋    | 135/235 [00:33<00:24,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.6212, Acc: 0.8398:  58%|█████▊    | 136/235 [00:33<00:24,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.5924, Acc: 0.8711:  58%|█████▊    | 136/235 [00:33<00:24,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.5924, Acc: 0.8711:  58%|█████▊    | 137/235 [00:33<00:24,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.5810, Acc: 0.8828:  58%|█████▊    | 137/235 [00:33<00:24,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.5810, Acc: 0.8828:  59%|█████▊    | 138/235 [00:33<00:23,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.6426, Acc: 0.8203:  59%|█████▊    | 138/235 [00:34<00:23,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.6426, Acc: 0.8203:  59%|█████▉    | 139/235 [00:34<00:23,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6007, Acc: 0.8633:  59%|█████▉    | 139/235 [00:34<00:23,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6007, Acc: 0.8633:  60%|█████▉    | 140/235 [00:34<00:23,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.5866, Acc: 0.8789:  60%|█████▉    | 140/235 [00:34<00:23,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.5866, Acc: 0.8789:  60%|██████    | 141/235 [00:34<00:23,  3.96step/s]\u001b[A\n",
            "[1/10] Loss: 1.6155, Acc: 0.8555:  60%|██████    | 141/235 [00:34<00:23,  3.96step/s]\u001b[A\n",
            "[1/10] Loss: 1.6155, Acc: 0.8555:  60%|██████    | 142/235 [00:34<00:23,  3.96step/s]\u001b[A\n",
            "[1/10] Loss: 1.5568, Acc: 0.9062:  60%|██████    | 142/235 [00:35<00:23,  3.96step/s]\u001b[A\n",
            "[1/10] Loss: 1.5568, Acc: 0.9062:  61%|██████    | 143/235 [00:35<00:23,  3.93step/s]\u001b[A\n",
            "[1/10] Loss: 1.6080, Acc: 0.8594:  61%|██████    | 143/235 [00:35<00:23,  3.93step/s]\u001b[A\n",
            "[1/10] Loss: 1.6080, Acc: 0.8594:  61%|██████▏   | 144/235 [00:35<00:23,  3.86step/s]\u001b[A\n",
            "[1/10] Loss: 1.6038, Acc: 0.8594:  61%|██████▏   | 144/235 [00:35<00:23,  3.86step/s]\u001b[A\n",
            "[1/10] Loss: 1.6038, Acc: 0.8594:  62%|██████▏   | 145/235 [00:35<00:22,  3.97step/s]\u001b[A\n",
            "[1/10] Loss: 1.6088, Acc: 0.8516:  62%|██████▏   | 145/235 [00:35<00:22,  3.97step/s]\u001b[A\n",
            "[1/10] Loss: 1.6088, Acc: 0.8516:  62%|██████▏   | 146/235 [00:35<00:22,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6087, Acc: 0.8594:  62%|██████▏   | 146/235 [00:36<00:22,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6087, Acc: 0.8594:  63%|██████▎   | 147/235 [00:36<00:21,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.5956, Acc: 0.8672:  63%|██████▎   | 147/235 [00:36<00:21,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.5956, Acc: 0.8672:  63%|██████▎   | 148/235 [00:36<00:21,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.6139, Acc: 0.8516:  63%|██████▎   | 148/235 [00:36<00:21,  4.01step/s]\u001b[A\n",
            "[1/10] Loss: 1.6139, Acc: 0.8516:  63%|██████▎   | 149/235 [00:36<00:21,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.5857, Acc: 0.8750:  63%|██████▎   | 149/235 [00:36<00:21,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.5857, Acc: 0.8750:  64%|██████▍   | 150/235 [00:36<00:20,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.5935, Acc: 0.8711:  64%|██████▍   | 150/235 [00:37<00:20,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.5935, Acc: 0.8711:  64%|██████▍   | 151/235 [00:37<00:20,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 1.6053, Acc: 0.8594:  64%|██████▍   | 151/235 [00:37<00:20,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 1.6053, Acc: 0.8594:  65%|██████▍   | 152/235 [00:37<00:20,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.6149, Acc: 0.8516:  65%|██████▍   | 152/235 [00:37<00:20,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.6149, Acc: 0.8516:  65%|██████▌   | 153/235 [00:37<00:20,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.5603, Acc: 0.9023:  65%|██████▌   | 153/235 [00:37<00:20,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.5603, Acc: 0.9023:  66%|██████▌   | 154/235 [00:37<00:20,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6049, Acc: 0.8594:  66%|██████▌   | 154/235 [00:38<00:20,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.6049, Acc: 0.8594:  66%|██████▌   | 155/235 [00:38<00:19,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6370, Acc: 0.8125:  66%|██████▌   | 155/235 [00:38<00:19,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6370, Acc: 0.8125:  66%|██████▋   | 156/235 [00:38<00:19,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.5919, Acc: 0.8633:  66%|██████▋   | 156/235 [00:38<00:19,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.5919, Acc: 0.8633:  67%|██████▋   | 157/235 [00:38<00:19,  3.97step/s]\u001b[A\n",
            "[1/10] Loss: 1.6445, Acc: 0.8164:  67%|██████▋   | 157/235 [00:38<00:19,  3.97step/s]\u001b[A\n",
            "[1/10] Loss: 1.6445, Acc: 0.8164:  67%|██████▋   | 158/235 [00:38<00:19,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.6334, Acc: 0.8320:  67%|██████▋   | 158/235 [00:39<00:19,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.6334, Acc: 0.8320:  68%|██████▊   | 159/235 [00:39<00:18,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6022, Acc: 0.8594:  68%|██████▊   | 159/235 [00:39<00:18,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6022, Acc: 0.8594:  68%|██████▊   | 160/235 [00:39<00:18,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.5811, Acc: 0.8867:  68%|██████▊   | 160/235 [00:39<00:18,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.5811, Acc: 0.8867:  69%|██████▊   | 161/235 [00:39<00:18,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.6109, Acc: 0.8477:  69%|██████▊   | 161/235 [00:39<00:18,  4.09step/s]\u001b[A\n",
            "[1/10] Loss: 1.6109, Acc: 0.8477:  69%|██████▉   | 162/235 [00:39<00:17,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.5955, Acc: 0.8633:  69%|██████▉   | 162/235 [00:40<00:17,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.5955, Acc: 0.8633:  69%|██████▉   | 163/235 [00:40<00:17,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 1.5630, Acc: 0.8945:  69%|██████▉   | 163/235 [00:40<00:17,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 1.5630, Acc: 0.8945:  70%|██████▉   | 164/235 [00:40<00:17,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6131, Acc: 0.8438:  70%|██████▉   | 164/235 [00:40<00:17,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6131, Acc: 0.8438:  70%|███████   | 165/235 [00:40<00:17,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.6001, Acc: 0.8633:  70%|███████   | 165/235 [00:40<00:17,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.6001, Acc: 0.8633:  71%|███████   | 166/235 [00:40<00:16,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.6227, Acc: 0.8438:  71%|███████   | 166/235 [00:41<00:16,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.6227, Acc: 0.8438:  71%|███████   | 167/235 [00:41<00:16,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6150, Acc: 0.8438:  71%|███████   | 167/235 [00:41<00:16,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6150, Acc: 0.8438:  71%|███████▏  | 168/235 [00:41<00:16,  4.15step/s]\u001b[A\n",
            "[1/10] Loss: 1.6363, Acc: 0.8242:  71%|███████▏  | 168/235 [00:41<00:16,  4.15step/s]\u001b[A\n",
            "[1/10] Loss: 1.6363, Acc: 0.8242:  72%|███████▏  | 169/235 [00:41<00:16,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6113, Acc: 0.8477:  72%|███████▏  | 169/235 [00:41<00:16,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6113, Acc: 0.8477:  72%|███████▏  | 170/235 [00:41<00:15,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.5821, Acc: 0.8828:  72%|███████▏  | 170/235 [00:42<00:15,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.5821, Acc: 0.8828:  73%|███████▎  | 171/235 [00:42<00:15,  4.15step/s]\u001b[A\n",
            "[1/10] Loss: 1.6264, Acc: 0.8359:  73%|███████▎  | 171/235 [00:42<00:15,  4.15step/s]\u001b[A\n",
            "[1/10] Loss: 1.6264, Acc: 0.8359:  73%|███████▎  | 172/235 [00:42<00:15,  4.20step/s]\u001b[A\n",
            "[1/10] Loss: 1.5886, Acc: 0.8750:  73%|███████▎  | 172/235 [00:42<00:15,  4.20step/s]\u001b[A\n",
            "[1/10] Loss: 1.5886, Acc: 0.8750:  74%|███████▎  | 173/235 [00:42<00:15,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.6058, Acc: 0.8633:  74%|███████▎  | 173/235 [00:42<00:15,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.6058, Acc: 0.8633:  74%|███████▍  | 174/235 [00:42<00:15,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6230, Acc: 0.8359:  74%|███████▍  | 174/235 [00:43<00:15,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6230, Acc: 0.8359:  74%|███████▍  | 175/235 [00:43<00:14,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.5992, Acc: 0.8672:  74%|███████▍  | 175/235 [00:43<00:14,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.5992, Acc: 0.8672:  75%|███████▍  | 176/235 [00:43<00:14,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.5902, Acc: 0.8828:  75%|███████▍  | 176/235 [00:43<00:14,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.5902, Acc: 0.8828:  75%|███████▌  | 177/235 [00:43<00:14,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6002, Acc: 0.8711:  75%|███████▌  | 177/235 [00:43<00:14,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6002, Acc: 0.8711:  76%|███████▌  | 178/235 [00:43<00:13,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6264, Acc: 0.8438:  76%|███████▌  | 178/235 [00:44<00:13,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6264, Acc: 0.8438:  76%|███████▌  | 179/235 [00:44<00:13,  4.12step/s]\u001b[A\n",
            "[1/10] Loss: 1.6218, Acc: 0.8359:  76%|███████▌  | 179/235 [00:44<00:13,  4.12step/s]\u001b[A\n",
            "[1/10] Loss: 1.6218, Acc: 0.8359:  77%|███████▋  | 180/235 [00:44<00:13,  4.15step/s]\u001b[A\n",
            "[1/10] Loss: 1.5967, Acc: 0.8672:  77%|███████▋  | 180/235 [00:44<00:13,  4.15step/s]\u001b[A\n",
            "[1/10] Loss: 1.5967, Acc: 0.8672:  77%|███████▋  | 181/235 [00:44<00:13,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.5715, Acc: 0.8906:  77%|███████▋  | 181/235 [00:44<00:13,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.5715, Acc: 0.8906:  77%|███████▋  | 182/235 [00:44<00:13,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6116, Acc: 0.8555:  77%|███████▋  | 182/235 [00:45<00:13,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6116, Acc: 0.8555:  78%|███████▊  | 183/235 [00:45<00:12,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6044, Acc: 0.8594:  78%|███████▊  | 183/235 [00:45<00:12,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6044, Acc: 0.8594:  78%|███████▊  | 184/235 [00:45<00:12,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6067, Acc: 0.8555:  78%|███████▊  | 184/235 [00:45<00:12,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.6067, Acc: 0.8555:  79%|███████▊  | 185/235 [00:45<00:12,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6184, Acc: 0.8516:  79%|███████▊  | 185/235 [00:45<00:12,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6184, Acc: 0.8516:  79%|███████▉  | 186/235 [00:45<00:12,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.6120, Acc: 0.8516:  79%|███████▉  | 186/235 [00:46<00:12,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.6120, Acc: 0.8516:  80%|███████▉  | 187/235 [00:46<00:11,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6115, Acc: 0.8477:  80%|███████▉  | 187/235 [00:46<00:11,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.6115, Acc: 0.8477:  80%|████████  | 188/235 [00:46<00:11,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6229, Acc: 0.8359:  80%|████████  | 188/235 [00:46<00:11,  4.05step/s]\u001b[A\n",
            "[1/10] Loss: 1.6229, Acc: 0.8359:  80%|████████  | 189/235 [00:46<00:11,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.5993, Acc: 0.8672:  80%|████████  | 189/235 [00:46<00:11,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.5993, Acc: 0.8672:  81%|████████  | 190/235 [00:46<00:11,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.6001, Acc: 0.8672:  81%|████████  | 190/235 [00:47<00:11,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.6001, Acc: 0.8672:  81%|████████▏ | 191/235 [00:47<00:10,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.5927, Acc: 0.8711:  81%|████████▏ | 191/235 [00:47<00:10,  4.03step/s]\u001b[A\n",
            "[1/10] Loss: 1.5927, Acc: 0.8711:  82%|████████▏ | 192/235 [00:47<00:10,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.5746, Acc: 0.8945:  82%|████████▏ | 192/235 [00:47<00:10,  4.06step/s]\u001b[A\n",
            "[1/10] Loss: 1.5746, Acc: 0.8945:  82%|████████▏ | 193/235 [00:47<00:10,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6008, Acc: 0.8672:  82%|████████▏ | 193/235 [00:47<00:10,  4.04step/s]\u001b[A\n",
            "[1/10] Loss: 1.6008, Acc: 0.8672:  83%|████████▎ | 194/235 [00:47<00:10,  3.97step/s]\u001b[A\n",
            "[1/10] Loss: 1.5983, Acc: 0.8672:  83%|████████▎ | 194/235 [00:48<00:10,  3.97step/s]\u001b[A\n",
            "[1/10] Loss: 1.5983, Acc: 0.8672:  83%|████████▎ | 195/235 [00:48<00:09,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6110, Acc: 0.8516:  83%|████████▎ | 195/235 [00:48<00:09,  4.02step/s]\u001b[A\n",
            "[1/10] Loss: 1.6110, Acc: 0.8516:  83%|████████▎ | 196/235 [00:48<00:09,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.6058, Acc: 0.8672:  83%|████████▎ | 196/235 [00:48<00:09,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.6058, Acc: 0.8672:  84%|████████▍ | 197/235 [00:48<00:09,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.6029, Acc: 0.8633:  84%|████████▍ | 197/235 [00:48<00:09,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.6029, Acc: 0.8633:  84%|████████▍ | 198/235 [00:48<00:09,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.6182, Acc: 0.8438:  84%|████████▍ | 198/235 [00:49<00:09,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.6182, Acc: 0.8438:  85%|████████▍ | 199/235 [00:49<00:08,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.5874, Acc: 0.8828:  85%|████████▍ | 199/235 [00:49<00:08,  4.08step/s]\u001b[A\n",
            "[1/10] Loss: 1.5874, Acc: 0.8828:  85%|████████▌ | 200/235 [00:49<00:08,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.6047, Acc: 0.8633:  85%|████████▌ | 200/235 [00:49<00:08,  4.10step/s]\u001b[A\n",
            "[1/10] Loss: 1.6047, Acc: 0.8633:  86%|████████▌ | 201/235 [00:49<00:08,  4.15step/s]\u001b[A\n",
            "[1/10] Loss: 1.6008, Acc: 0.8633:  86%|████████▌ | 201/235 [00:49<00:08,  4.15step/s]\u001b[A\n",
            "[1/10] Loss: 1.6008, Acc: 0.8633:  86%|████████▌ | 202/235 [00:49<00:07,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 1.5835, Acc: 0.8789:  86%|████████▌ | 202/235 [00:49<00:07,  4.14step/s]\u001b[A\n",
            "[1/10] Loss: 1.5835, Acc: 0.8789:  86%|████████▋ | 203/235 [00:49<00:07,  4.12step/s]\u001b[A\n",
            "[1/10] Loss: 1.6162, Acc: 0.8516:  86%|████████▋ | 203/235 [00:50<00:07,  4.12step/s]\u001b[A\n",
            "[1/10] Loss: 1.6162, Acc: 0.8516:  87%|████████▋ | 204/235 [00:50<00:07,  4.18step/s]\u001b[A\n",
            "[1/10] Loss: 1.5972, Acc: 0.8633:  87%|████████▋ | 204/235 [00:50<00:07,  4.18step/s]\u001b[A\n",
            "[1/10] Loss: 1.5972, Acc: 0.8633:  87%|████████▋ | 205/235 [00:50<00:07,  4.18step/s]\u001b[A\n",
            "[1/10] Loss: 1.6351, Acc: 0.8242:  87%|████████▋ | 205/235 [00:50<00:07,  4.18step/s]\u001b[A\n",
            "[1/10] Loss: 1.6351, Acc: 0.8242:  88%|████████▊ | 206/235 [00:50<00:06,  4.17step/s]\u001b[A\n",
            "[1/10] Loss: 1.6018, Acc: 0.8633:  88%|████████▊ | 206/235 [00:50<00:06,  4.17step/s]\u001b[A\n",
            "[1/10] Loss: 1.6018, Acc: 0.8633:  88%|████████▊ | 207/235 [00:50<00:06,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.5605, Acc: 0.9023:  88%|████████▊ | 207/235 [00:51<00:06,  4.11step/s]\u001b[A\n",
            "[1/10] Loss: 1.5605, Acc: 0.9023:  89%|████████▊ | 208/235 [00:51<00:06,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 1.5716, Acc: 0.8945:  89%|████████▊ | 208/235 [00:51<00:06,  4.13step/s]\u001b[A\n",
            "[1/10] Loss: 1.5716, Acc: 0.8945:  89%|████████▉ | 209/235 [00:51<00:06,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6214, Acc: 0.8477:  89%|████████▉ | 209/235 [00:51<00:06,  4.07step/s]\u001b[A\n",
            "[1/10] Loss: 1.6214, Acc: 0.8477:  89%|████████▉ | 210/235 [00:51<00:06,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.6166, Acc: 0.8477:  89%|████████▉ | 210/235 [00:51<00:06,  4.00step/s]\u001b[A\n",
            "[1/10] Loss: 1.6166, Acc: 0.8477:  90%|████████▉ | 211/235 [00:51<00:06,  3.95step/s]\u001b[A\n",
            "[1/10] Loss: 1.6346, Acc: 0.8203:  90%|████████▉ | 211/235 [00:52<00:06,  3.95step/s]\u001b[A\n",
            "[1/10] Loss: 1.6346, Acc: 0.8203:  90%|█████████ | 212/235 [00:52<00:05,  3.91step/s]\u001b[A\n",
            "[1/10] Loss: 1.5903, Acc: 0.8750:  90%|█████████ | 212/235 [00:52<00:05,  3.91step/s]\u001b[A\n",
            "[1/10] Loss: 1.5903, Acc: 0.8750:  91%|█████████ | 213/235 [00:52<00:05,  3.97step/s]\u001b[A\n",
            "[1/10] Loss: 1.6007, Acc: 0.8555:  91%|█████████ | 213/235 [00:52<00:05,  3.97step/s]\u001b[A\n",
            "[1/10] Loss: 1.6007, Acc: 0.8555:  91%|█████████ | 214/235 [00:52<00:05,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.5971, Acc: 0.8594:  91%|█████████ | 214/235 [00:52<00:05,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.5971, Acc: 0.8594:  91%|█████████▏| 215/235 [00:52<00:05,  3.96step/s]\u001b[A\n",
            "[1/10] Loss: 1.6078, Acc: 0.8516:  91%|█████████▏| 215/235 [00:53<00:05,  3.96step/s]\u001b[A\n",
            "[1/10] Loss: 1.6078, Acc: 0.8516:  92%|█████████▏| 216/235 [00:53<00:04,  3.94step/s]\u001b[A\n",
            "[1/10] Loss: 1.5969, Acc: 0.8633:  92%|█████████▏| 216/235 [00:53<00:04,  3.94step/s]\u001b[A\n",
            "[1/10] Loss: 1.5969, Acc: 0.8633:  92%|█████████▏| 217/235 [00:53<00:04,  3.81step/s]\u001b[A\n",
            "[1/10] Loss: 1.5887, Acc: 0.8789:  92%|█████████▏| 217/235 [00:53<00:04,  3.81step/s]\u001b[A\n",
            "[1/10] Loss: 1.5887, Acc: 0.8789:  93%|█████████▎| 218/235 [00:53<00:04,  3.81step/s]\u001b[A\n",
            "[1/10] Loss: 1.5831, Acc: 0.8828:  93%|█████████▎| 218/235 [00:54<00:04,  3.81step/s]\u001b[A\n",
            "[1/10] Loss: 1.5831, Acc: 0.8828:  93%|█████████▎| 219/235 [00:54<00:04,  3.82step/s]\u001b[A\n",
            "[1/10] Loss: 1.5702, Acc: 0.8984:  93%|█████████▎| 219/235 [00:54<00:04,  3.82step/s]\u001b[A\n",
            "[1/10] Loss: 1.5702, Acc: 0.8984:  94%|█████████▎| 220/235 [00:54<00:03,  3.86step/s]\u001b[A\n",
            "[1/10] Loss: 1.5723, Acc: 0.8945:  94%|█████████▎| 220/235 [00:54<00:03,  3.86step/s]\u001b[A\n",
            "[1/10] Loss: 1.5723, Acc: 0.8945:  94%|█████████▍| 221/235 [00:54<00:03,  3.90step/s]\u001b[A\n",
            "[1/10] Loss: 1.5745, Acc: 0.8867:  94%|█████████▍| 221/235 [00:54<00:03,  3.90step/s]\u001b[A\n",
            "[1/10] Loss: 1.5745, Acc: 0.8867:  94%|█████████▍| 222/235 [00:54<00:03,  3.87step/s]\u001b[A\n",
            "[1/10] Loss: 1.6032, Acc: 0.8633:  94%|█████████▍| 222/235 [00:55<00:03,  3.87step/s]\u001b[A\n",
            "[1/10] Loss: 1.6032, Acc: 0.8633:  95%|█████████▍| 223/235 [00:55<00:03,  3.89step/s]\u001b[A\n",
            "[1/10] Loss: 1.5896, Acc: 0.8789:  95%|█████████▍| 223/235 [00:55<00:03,  3.89step/s]\u001b[A\n",
            "[1/10] Loss: 1.5896, Acc: 0.8789:  95%|█████████▌| 224/235 [00:55<00:02,  3.97step/s]\u001b[A\n",
            "[1/10] Loss: 1.6176, Acc: 0.8438:  95%|█████████▌| 224/235 [00:55<00:02,  3.97step/s]\u001b[A\n",
            "[1/10] Loss: 1.6176, Acc: 0.8438:  96%|█████████▌| 225/235 [00:55<00:02,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.6135, Acc: 0.8477:  96%|█████████▌| 225/235 [00:55<00:02,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.6135, Acc: 0.8477:  96%|█████████▌| 226/235 [00:55<00:02,  3.96step/s]\u001b[A\n",
            "[1/10] Loss: 1.5790, Acc: 0.8828:  96%|█████████▌| 226/235 [00:56<00:02,  3.96step/s]\u001b[A\n",
            "[1/10] Loss: 1.5790, Acc: 0.8828:  97%|█████████▋| 227/235 [00:56<00:02,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.5973, Acc: 0.8711:  97%|█████████▋| 227/235 [00:56<00:02,  3.99step/s]\u001b[A\n",
            "[1/10] Loss: 1.5973, Acc: 0.8711:  97%|█████████▋| 228/235 [00:56<00:01,  3.91step/s]\u001b[A\n",
            "[1/10] Loss: 1.5983, Acc: 0.8633:  97%|█████████▋| 228/235 [00:56<00:01,  3.91step/s]\u001b[A\n",
            "[1/10] Loss: 1.5983, Acc: 0.8633:  97%|█████████▋| 229/235 [00:56<00:01,  3.89step/s]\u001b[A\n",
            "[1/10] Loss: 1.6011, Acc: 0.8633:  97%|█████████▋| 229/235 [00:56<00:01,  3.89step/s]\u001b[A\n",
            "[1/10] Loss: 1.6011, Acc: 0.8633:  98%|█████████▊| 230/235 [00:56<00:01,  3.87step/s]\u001b[A\n",
            "[1/10] Loss: 1.6099, Acc: 0.8555:  98%|█████████▊| 230/235 [00:57<00:01,  3.87step/s]\u001b[A\n",
            "[1/10] Loss: 1.6099, Acc: 0.8555:  98%|█████████▊| 231/235 [00:57<00:01,  3.82step/s]\u001b[A\n",
            "[1/10] Loss: 1.5906, Acc: 0.8789:  98%|█████████▊| 231/235 [00:57<00:01,  3.82step/s]\u001b[A\n",
            "[1/10] Loss: 1.5906, Acc: 0.8789:  99%|█████████▊| 232/235 [00:57<00:00,  3.76step/s]\u001b[A\n",
            "[1/10] Loss: 1.5735, Acc: 0.8867:  99%|█████████▊| 232/235 [00:57<00:00,  3.76step/s]\u001b[A\n",
            "[1/10] Loss: 1.5735, Acc: 0.8867:  99%|█████████▉| 233/235 [00:57<00:00,  3.71step/s]\u001b[A\n",
            "[1/10] Loss: 1.6262, Acc: 0.8398:  99%|█████████▉| 233/235 [00:57<00:00,  3.71step/s]\u001b[A\n",
            "[1/10] Loss: 1.6262, Acc: 0.8398: 100%|█████████▉| 234/235 [00:57<00:00,  3.72step/s]\u001b[A\n",
            "[1/10] Loss: 1.6333, Acc: 0.8333: 100%|█████████▉| 234/235 [00:58<00:00,  3.72step/s]\u001b[A\n",
            "[1/10] Loss: 1.5865, Acc: 0.8333, Test Loss: 1.5875, Test Acc: 0.8542: 100%|█████████▉| 234/235 [01:03<00:00,  3.72step/s]\u001b[A\n",
            "[1/10] Loss: 1.5865, Acc: 0.8333, Test Loss: 1.5875, Test Acc: 0.8542: 100%|██████████| 235/235 [01:03<00:00,  3.71step/s]\n",
            "[2/10] Loss: 1.4612, Acc: 0.9375, Test Loss: 1.4854, Test Acc: 0.9541: 100%|██████████| 235/235 [00:58<00:00,  4.00step/s]\n",
            "[3/10] Loss: 1.4613, Acc: 0.9896, Test Loss: 1.4775, Test Acc: 0.9614: 100%|██████████| 235/235 [00:58<00:00,  4.04step/s]\n",
            "[4/10] Loss: 1.4612, Acc: 1.0000, Test Loss: 1.4793, Test Acc: 0.9591: 100%|██████████| 235/235 [00:58<00:00,  4.04step/s]\n",
            "[5/10] Loss: 1.4612, Acc: 0.9583, Test Loss: 1.4752, Test Acc: 0.9635: 100%|██████████| 235/235 [00:57<00:00,  4.06step/s]\n",
            "[6/10] Loss: 1.4612, Acc: 0.9896, Test Loss: 1.4762, Test Acc: 0.9621: 100%|██████████| 235/235 [00:56<00:00,  4.12step/s]\n",
            "[7/10] Loss: 1.4612, Acc: 0.9792, Test Loss: 1.4723, Test Acc: 0.9658: 100%|██████████| 235/235 [00:58<00:00,  3.99step/s]\n",
            "[8/10] Loss: 1.4623, Acc: 0.9896, Test Loss: 1.4726, Test Acc: 0.9656: 100%|██████████| 235/235 [00:58<00:00,  4.02step/s]\n",
            "[9/10] Loss: 1.4612, Acc: 0.9896, Test Loss: 1.4719, Test Acc: 0.9659: 100%|██████████| 235/235 [00:58<00:00,  4.01step/s]\n",
            "[10/10] Loss: 1.4612, Acc: 0.9896, Test Loss: 1.4708, Test Acc: 0.9673: 100%|██████████| 235/235 [00:58<00:00,  4.05step/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "item = testDataLoader.dataset.data[0]\n",
        "im = Image.fromarray(item.numpy())\n",
        "im.save('7.bmp', 'bmp')\n"
      ],
      "metadata": {
        "id": "q46OavEAnW7R"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "train_transform = transforms.Compose([\n",
        "         transforms.Grayscale(),\n",
        "         transforms.Resize((28, 28)),\n",
        "         transforms.ToTensor(),\n",
        "         ])\n",
        "im = Image.open('7.bmp')\n",
        "imdata = train_transform(im)\n",
        "print(imdata.shape)\n",
        "imdata = torch.unsqueeze(imdata, dim=0)\n",
        "print(imdata.shape)\n",
        "\n",
        "outputs = net(imdata)\n",
        "predictions = torch.argmax(outputs, dim = 1)\n",
        "\n",
        "print(predictions)\n",
        "\n",
        "plt.imshow(im, cmap='gray')\n",
        "predict = predictions[0]\n",
        "plt.title(f'${predict}')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "DB-r6bYYnwHl",
        "outputId": "63aaf736-def6-402b-ca9a-8476805af81e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([1, 1, 28, 28])\n",
            "tensor([7])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(net,'./model.pth')\n",
        "item = testDataLoader.dataset.data[0]\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "for testImgs,labels in testDataLoader:\n",
        "    testImgs = testImgs.to(device)\n",
        "    print(testImgs.shape)\n",
        "    image = torch.unsqueeze(testImgs[0], dim=0)\n",
        "    print(image.shape)\n",
        "    labels = labels.to(device)\n",
        "    outputs = net(image)\n",
        "    predictions = torch.argmax(outputs, dim = 1)\n",
        "    print(labels)\n",
        "    print(predictions)\n",
        "    item = item.numpy()\n",
        "    print(item.shape)\n",
        "    # item = item.reshape(28, 28, 1)\n",
        "    plt.imshow(testImgs[0][0].numpy(), cmap='gray')\n",
        "    predit = predictions[0]\n",
        "    # plt.title(f'${predict}')\n",
        "    plt.show()\n",
        "\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "id": "bCj_pF2xWngn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "u_FJUDWlnTqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item = testDataLoader.dataset.data[0]\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# print(item)\n",
        "\n",
        "image = item.numpy()\n",
        "# print(image)\n",
        "# image = image.reshape(28, 28, 1)\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ixPCxrfcdNro",
        "outputId": "a6278824-ccab-444e-9d4d-7e84e0b9b8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testDataLoader.dataset.test_labels[0].numpy())\n",
        "outputs = net(torch.unsqueeze(item, dim=0))\n",
        "predictions = torch.argmax(outputs,dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "mUxDSlhafSMq",
        "outputId": "c4a4e113-b42c-4832-e3e7-341dbe598ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-a3bdc2be7fb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestDataLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-20efd3c9427b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [16, 1, 3, 3], but got 3-dimensional input of size [1, 28, 28] instead"
          ]
        }
      ]
    }
  ]
}